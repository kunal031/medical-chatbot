{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00eb0ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kunal/VsCode/Python/medical-chatbot/research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac9b7940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\") # change directory to load book from data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6eb03fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kunal/VsCode/Python/medical-chatbot'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d3ec127",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader,DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # for chunk operation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4c49235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Data from the PDF file\n",
    "\n",
    "def load_pdf_file(data):\n",
    "  loader = DirectoryLoader(data,\n",
    "                           glob = \"*.pdf\",\n",
    "                           loader_cls = PyPDFLoader)\n",
    "\n",
    "  documents=loader.load()\n",
    "  return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c0b3b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf_file(data='/Users/kunal/VsCode/Python/medical-chatbot/Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f0cd0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4128232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into the text Chunks\n",
    "def text_split(extracted_data):\n",
    "  text_splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=20)\n",
    "  text_chunks=text_splitter.split_documents(extracted_data)\n",
    "  return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a08057bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text Chunks :  40000\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"Length of Text Chunks : \", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f070c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5c011c",
   "metadata": {},
   "source": [
    "Now I have to use a embedding model to perform vector embeddings over text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c6108c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac4b020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Embeddings from Hugging Face\n",
    "\n",
    "def download_hugging_face_embeddings():\n",
    "  embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "  return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "460ac7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gm/dlyx0css1pg01nh9plvcnlmm0000gn/T/ipykernel_64310/2967380959.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
      "/Users/kunal/VsCode/Python/medical-chatbot/medibot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading .gitattributes: 1.23kB [00:00, 1.05MB/s]\n",
      "Downloading config.json: 100%|██████████| 190/190 [00:00<00:00, 562kB/s]\n",
      "Downloading README.md: 10.5kB [00:00, 10.6MB/s]\n",
      "Downloading config.json: 100%|██████████| 612/612 [00:00<00:00, 3.54MB/s]\n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 264kB/s]\n",
      "Downloading data_config.json: 39.3kB [00:00, 21.9MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 90.9M/90.9M [00:14<00:00, 6.47MB/s]\n",
      "Downloading model.onnx: 100%|██████████| 90.4M/90.4M [00:15<00:00, 5.70MB/s]\n",
      "Downloading model_O1.onnx: 100%|██████████| 90.4M/90.4M [00:11<00:00, 7.85MB/s]\n",
      "Downloading model_O2.onnx: 100%|██████████| 90.3M/90.3M [00:11<00:00, 8.20MB/s]\n",
      "Downloading model_O3.onnx: 100%|██████████| 90.3M/90.3M [00:10<00:00, 8.79MB/s]\n",
      "Downloading model_O4.onnx: 100%|██████████| 45.2M/45.2M [00:05<00:00, 8.34MB/s]\n",
      "Downloading model_qint8_arm64.onnx: 100%|██████████| 23.0M/23.0M [00:02<00:00, 9.67MB/s]\n",
      "Downloading (…)el_qint8_avx512.onnx: 100%|██████████| 23.0M/23.0M [00:03<00:00, 6.52MB/s]\n",
      "Downloading (…)nt8_avx512_vnni.onnx: 100%|██████████| 23.0M/23.0M [00:03<00:00, 7.47MB/s]\n",
      "Downloading model_quint8_avx2.onnx: 100%|██████████| 23.0M/23.0M [00:01<00:00, 12.5MB/s]\n",
      "Downloading openvino_model.bin: 100%|██████████| 90.3M/90.3M [00:10<00:00, 8.46MB/s]\n",
      "Downloading openvino_model.xml: 211kB [00:00, 76.7MB/s]\n",
      "Downloading (…)_qint8_quantized.bin: 100%|██████████| 22.9M/22.9M [00:01<00:00, 12.0MB/s]\n",
      "Downloading (…)_qint8_quantized.xml: 368kB [00:00, 12.5MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:10<00:00, 8.46MB/s]\n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 183kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 358kB/s]\n",
      "Downloading tokenizer.json: 466kB [00:00, 1.32MB/s]\n",
      "Downloading tokenizer_config.json: 100%|██████████| 350/350 [00:00<00:00, 1.42MB/s]\n",
      "Downloading train_script.py: 13.2kB [00:00, 6.15MB/s]\n",
      "Downloading vocab.txt: 232kB [00:00, 4.29MB/s]\n",
      "Downloading modules.json: 100%|██████████| 349/349 [00:00<00:00, 1.18MB/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5b4deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "# vector = embeddings.embed_query(\"medical chatbot test\")\n",
    "\n",
    "# print(\"Embedding dimension:\", len(vector))  # should print 384\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe0eed5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vector = embeddings.embed_query(\"medical chatbot test\")\n",
    "\n",
    "print(\"Embedding dimension:\", len(vector))  # should print 384\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1209d4f5",
   "metadata": {},
   "source": [
    "## Creating knowledge base from embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71296f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "021c4415",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94ed8328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"medicalbot\",\n",
       "    \"metric\": \"cosine\",\n",
       "    \"host\": \"medicalbot-6y1c00f.svc.aped-4627-b74a.pinecone.io\",\n",
       "    \"spec\": {\n",
       "        \"serverless\": {\n",
       "            \"cloud\": \"aws\",\n",
       "            \"region\": \"us-east-1\"\n",
       "        }\n",
       "    },\n",
       "    \"status\": {\n",
       "        \"ready\": true,\n",
       "        \"state\": \"Ready\"\n",
       "    },\n",
       "    \"vector_type\": \"dense\",\n",
       "    \"dimension\": 384,\n",
       "    \"deletion_protection\": \"disabled\",\n",
       "    \"tags\": null\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone \n",
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"medicalbot\"\n",
    "\n",
    "pc.create_index(\n",
    "  name=index_name,\n",
    "  dimension=384,\n",
    "  metric=\"cosine\",\n",
    "  spec=ServerlessSpec(\n",
    "    cloud=\"aws\",\n",
    "    region=\"us-east-1\"\n",
    "  )\n",
    ")\n",
    "\n",
    "# after executing this code, index is automatically created  in pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ca0a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5168d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed each chunk and upsert the embeddings into our Pinecone Index\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "  documents=text_chunks,\n",
    "  index_name=index_name,\n",
    "  embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274a8a75",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "762e6317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Existing Index\n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "  index_name=index_name,\n",
    "  embedding=embeddings\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b96eb601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x30c5b7e20>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1700200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1009398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# asking questions\n",
    "retrieved_docs = retriever.invoke(\"What is Acne?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3319e762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='fc8a5e6b-6d80-4da4-9ada-8e4fd59266ea', metadata={'creationdate': '2006-10-16T20:19:33+02:00', 'creator': 'Adobe Acrobat 6.0', 'moddate': '2006-10-16T22:03:45+02:00', 'page': 55.0, 'page_label': '26', 'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'source': '/Users/kunal/VsCode/Python/medical-chatbot/Data/The-Gale-Encyclopedia-of-Medicine-3rd-Edition-staibabussalamsula.ac_.id_.pdf', 'total_pages': 4505.0}, page_content='Researchers, Inc. Reproduced by permission.)\\n26 GALE ENCYCLOPEDIA OF MEDICINE\\nAcne'),\n",
       " Document(id='587ddd11-3795-443d-b40b-42bf47669395', metadata={'creationdate': '2006-10-16T20:19:33+02:00', 'creator': 'Adobe Acrobat 6.0', 'moddate': '2006-10-16T22:03:45+02:00', 'page': 55.0, 'page_label': '26', 'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'source': '/Users/kunal/VsCode/Python/medical-chatbot/Data/The-Gale-Encyclopedia-of-Medicine-3rd-Edition-staibabussalamsula.ac_.id_.pdf', 'total_pages': 4505.0}, page_content='Sebaceous follicles— A structure found within the\\nskin that houses the oil-producing glands and hair\\nfollicles, where pimples form.\\nSebum— An oily skin moisturizer produced by\\nsebaceous glands.\\nTretinoin— A drug that works by increasing the\\nturnover (death and replacement) of skin cells.\\nAcne vulgaris affecting a woman’s face. Acne is the general\\nname given to a skin disorder in which the sebaceous glands\\nbecome inflamed. (Photograph by Biophoto Associates, Photo'),\n",
       " Document(id='4ab0997f-797f-46b7-8674-648ec5139d38', metadata={'creationdate': '2006-10-16T20:19:33+02:00', 'creator': 'Adobe Acrobat 6.0', 'moddate': '2006-10-16T22:03:45+02:00', 'page': 54.0, 'page_label': '25', 'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'source': '/Users/kunal/VsCode/Python/medical-chatbot/Data/The-Gale-Encyclopedia-of-Medicine-3rd-Edition-staibabussalamsula.ac_.id_.pdf', 'total_pages': 4505.0}, page_content='Pathological Stage and Recurrence in Radical\\nProstatectomy Cases.’’Journal of Urology (March\\n1998): 935-940.\\nNancy J. Nordenson\\nAcid reflux see Heartburn\\nAcidosis see Respiratory acidosis; Renal\\ntubular acidosis; Metabolic acidosis\\nAcne\\nDefinition\\nAcne is a common skin disease characterized by\\npimples on the face, chest, and back. It occurs when\\nthe pores of the skin become clogged with oil, dead\\nskin cells, and bacteria.\\nDescription\\nAcne vulgaris, the medical term for common acne,')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827e304a",
   "metadata": {},
   "source": [
    "## Now Intitalize llm model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac67520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import OpenAI\n",
    "# llm = OpenAI(temperature=0.4,max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f40bce94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"mistral\",                # the model you pulled with Ollama\n",
    "    temperature=0.4,\n",
    "    max_tokens=500,\n",
    "    openai_api_key=\"NA\",            # dummy key (not needed for Ollama)\n",
    "    openai_api_base=\"http://localhost:11434/v1\"  # Ollama's OpenAI-like endpoint\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "702d2db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains import create_retrieval_chain\n",
    "# from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# ### ROle of RAG Application . That I need to know\n",
    "\n",
    "# system_prompt = (\n",
    "#   \"You are an assistant for question_answering tasks. \"\n",
    "#   \"Use the following pieces of retrieved context to answer \"\n",
    "#   \"the question. If you don't know the answer, say that you \"\n",
    "#   \"don't know. Use three sentences maximumand keep the \"\n",
    "#   \"answer concise. \"\n",
    "#   \"\\n\\n\"\n",
    "#   \"{context}\"\n",
    "# )\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#   [\n",
    "#     (\"system\", system_prompt),\n",
    "#     (\"human\", \"{input}\"),\n",
    "#   ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f76c9060",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "  \"You are an assistant for question_answering tasks. \"\n",
    "  \"Use the following pieces of retrieved context to answer \"\n",
    "  \"the question. If you don't know the answer, say that you \"\n",
    "  \"don't know. Use three sentences maximum and keep the \"\n",
    "  \"answer concise. \"\n",
    "  \"\\n\\n\"\n",
    "  \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "  ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7956f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "# rag_chain = create_retrieval_chain(retriever,question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe8decbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8793ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = rag_chain.invoke({\"input\" : \"What is Acne?\"})\n",
    "# print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cad442ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To detoxify from smoking weed, you should follow these steps:\n",
      "\n",
      "1. Abstain from using weed completely for a period of time (usually several weeks) to allow the body to eliminate the remaining THC (the active ingredient in marijuana).\n",
      "2. Eliminate exposure to all toxic substances, including cannabis smoke, chemicals, and other pollutants.\n",
      "3. Maintain a healthy diet and exercise regularly to aid in the detoxification process and support overall health.\n",
      "4. After detoxification, it's important to consider seeking professional help for addiction treatment and long-term recovery programs to prevent relapse.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"I used to smoke weed daily and now I want to detox myself .. what i need to do ?\"})\n",
    "print(response[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d650542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
